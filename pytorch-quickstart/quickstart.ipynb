{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_marker": "\"\"\""
      },
      "source": [
        "PyTorch: Quick Start\n",
        "====================\n",
        "\n",
        "In this tutorial, we are going to deploy a [PyTorch image classification\n",
        "model](https://pytorch.org/hub/pytorch_vision_mobilenet_v2/) to Model Zoo and\n",
        "use it to make a prediction. The Model Zoo client library relies on the [ONNX\n",
        "format](https://onnx.ai/) to serialize models.\n",
        "\n",
        "You can follow along this tutorial in any Python environment you're comfortable\n",
        "with, such as a Python IDE, Jupyter notebook, or a Python terminal. The easiest\n",
        "option is to open this tutorial directly in colab:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/model-zoo/examples/blob/master/pytorch-quickstart/quickstart.ipynb)\n",
        "\n",
        "Installation\n",
        "------------\n",
        "\n",
        "Install the Model Zoo client library via pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install modelzoo-client[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_marker": "##############################################################################"
      },
      "source": [
        "\n",
        "To deploy and use your own models, you'll need to create an account and\n",
        "configure an API key. You can do so from the command line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!modelzoo auth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_marker": "##############################################################################"
      },
      "source": [
        "\n",
        "Load\n",
        "----\n",
        "\n",
        "First, we'll need a PyTorch model (`nn.Module`) to deploy. For the sake of\n",
        "this quickstart, we'll use the ``torchvision`` package to load a pretrained\n",
        "[Mobile Net V2 image classification\n",
        "model](https://pytorch.org/hub/pytorch_vision_mobilenet_v2/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "model = torchvision.models.mobilenet_v2(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_marker": "##############################################################################"
      },
      "source": [
        "\n",
        "Deploy\n",
        "------\n",
        "\n",
        "To deploy this pipeline to a production-ready HTTP endpoint, use the\n",
        "[`modelzoo.torch.deploy()`](https://docs.modelzoo.dev/reference/modelzoo.torch.html#modelzoo.torch.deploy)\n",
        "function. Since the Model Zoo PyTorch client library relies on the ONNX\n",
        "format for serialization. `modelzoo.torch.deploy()` uses the same arguments\n",
        "as\n",
        "[`torch.onnx.export()`](https://pytorch.org/docs/stable/onnx.html#torch.onnx.export),\n",
        "except that it does not require a filename. Instead, the ONNX-serialized\n",
        "model will be directly uploaded to Model Zoo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import modelzoo.torch\n",
        "\n",
        "model_name = modelzoo.torch.deploy(\n",
        "    model, torch.randn(1, 3, 224, 224), input_names=[\"input\"], output_names=[\"output\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_marker": "##############################################################################"
      },
      "source": [
        "\n",
        "That's all there is to it! Behind the scenes, Model Zoo serialized your model\n",
        "to ONNX, uploaded it to object storage, deployed a container to serve any\n",
        "HTTP requests made to the model, and set up a load balancer to route requests\n",
        "to multiple model shards. If you'd like, take some time to explore the model\n",
        "via the Web UI link. There you'll be able to modify documentation, test the\n",
        "model with raw or visual inputs, monitor metrics and/or logs. By default,\n",
        "only your account (or anybody you share your API key with) will be able to\n",
        "access this model.\n",
        "\n",
        "You can specify the name of the model you'd like to deploy via a ``model_name``\n",
        "argument. If a name is omitted, Model Zoo will choose a unique one for you.\n",
        "Model names must be unique to your account.\n",
        "\n",
        "Predict\n",
        "-------\n",
        "\n",
        "First, let's load a picture of a dog to use as a test for the image\n",
        "classification model. We'll also load the JSON metadata that maps the class\n",
        "indices to human-readable labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "image_response = requests.get(\n",
        "    \"https://modelzoo-datasets.s3-us-west-2.amazonaws.com/imagenet/dog.jpg\"\n",
        ")\n",
        "input_image = Image.open(BytesIO(image_response.content))\n",
        "\n",
        "class_to_labels = requests.get(\n",
        "    \"https://modelzoo-datasets.s3-us-west-2.amazonaws.com/imagenet/class_idx_to_labels.json\"\n",
        ").json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_marker": "##############################################################################"
      },
      "source": [
        "\n",
        "![](https://modelzoo-datasets.s3-us-west-2.amazonaws.com/imagenet/dog.jpg)\n",
        "\n",
        "Next, we'll use our Python client library to query the model for a\n",
        "prediction.\n",
        "[`modelzoo.torch.predict()`](https://docs.modelzoo.dev/reference/modelzoo.torch.html#modelzoo.torch.predict)\n",
        "requires the `model_name` and a Python dictionary mapping input layer string\n",
        "names to a dictionary in\n",
        "[onnx.TensorProto](https://github.com/onnx/onnx/blob/9b7c2b4f0b4a16a0cf31145eae9425abe7cbe2a9/onnx/onnx-ml.proto#L451)\n",
        "format. In this example, we'll also transform the input image and apply the\n",
        "appropriate transformations as specified by the [model\n",
        "documentation](https://pytorch.org/hub/pytorch_vision_mobilenet_v2/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import modelzoo.torch\n",
        "import numpy as np\n",
        "\n",
        "import onnx\n",
        "from torchvision import transforms\n",
        "\n",
        "preprocess = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")\n",
        "input_tensor = preprocess(input_image)\n",
        "input_tensor = input_tensor.unsqueeze(0)\n",
        "\n",
        "full_output = modelzoo.torch.predict(\n",
        "    model_name,\n",
        "    {\n",
        "        \"input\": {\n",
        "            \"dims\": input_tensor.shape,\n",
        "            \"data_type\": onnx.TensorProto.DataType.FLOAT,\n",
        "            \"float_data\": input_tensor.numpy().tolist(),\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "output = full_output[\"outputs\"][\"output\"][\"floatData\"]\n",
        "model_prediction_idx = str(np.argmax(output))\n",
        "print(\"Model prediction: {}\".format(class_to_labels[model_prediction_idx]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_marker": "##############################################################################"
      },
      "source": [
        "\n",
        "Great! At this point, we've used our image classification model to\n",
        "successfully make a prediction on a new image.\n",
        "\n",
        "Manage\n",
        "------\n",
        "\n",
        "By default, Model Zoo will deploy your model and wait for it to get into a\n",
        "`HEALTHY` state, meaning that it's ready for predictions. You can always\n",
        "check on the state of a model by using the\n",
        "[`modelzoo.info()`](https://docs.modelzoo.dev/reference/modelzoo.html#modelzoo.info)\n",
        "function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelzoo.info(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_marker": "##############################################################################"
      },
      "source": [
        "\n",
        "To save resources and shut down any model if you aren't using it, you can use\n",
        "[`modelzoo.stop()`](https://docs.modelzoo.dev/reference/modelzoo.html#modelzoo.stop):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelzoo.stop(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_marker": "##############################################################################"
      },
      "source": [
        "\n",
        "With Model Zoo you can manage model state manually, or automatically. By\n",
        "default, our free trial will stop any model where there has been no request\n",
        "activity for 15 minutes, saving you resources if you forget to stop manually.\n",
        "Our unlimited version has more options for controlling autoscaling behavior.\n",
        "\n",
        "Interested in what you've seen and want to test drive an unlimited version of\n",
        "Model Zoo? Apply to our [private\n",
        "beta](https://modelzoo.typeform.com/to/Y8U9Lw) and reach out at\n",
        "[contact@modelzoo.dev](mailto:contact@modelzoo.dev) to learn more."
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
